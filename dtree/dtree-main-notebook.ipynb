{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45dde061",
   "metadata": {
    "id": "EhK1f5uMqm_4",
    "papermill": {
     "duration": 0.014592,
     "end_time": "2024-07-04T11:04:59.759255",
     "exception": false,
     "start_time": "2024-07-04T11:04:59.744663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31257774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:04:59.791818Z",
     "iopub.status.busy": "2024-07-04T11:04:59.790990Z",
     "iopub.status.idle": "2024-07-04T11:05:15.042031Z",
     "shell.execute_reply": "2024-07-04T11:05:15.040917Z"
    },
    "id": "9y1X1vpKq88O",
    "outputId": "e50c0458-a807-49bc-d7f2-cf5088bba55d",
    "papermill": {
     "duration": 15.268882,
     "end_time": "2024-07-04T11:05:15.044432",
     "exception": false,
     "start_time": "2024-07-04T11:04:59.775550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (1.4.2)\r\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\r\n",
      "Collecting ta\r\n",
      "  Downloading ta-0.11.0.tar.gz (25 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting vnstock\r\n",
      "  Downloading vnstock-0.2.9.0-py3-none-any.whl.metadata (7.9 kB)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.4)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.11.4)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from ta) (2.2.2)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->ta) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->ta) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->ta) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\r\n",
      "Downloading vnstock-0.2.9.0-py3-none-any.whl (37 kB)\r\n",
      "Building wheels for collected packages: ta\r\n",
      "  Building wheel for ta (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29413 sha256=16963c882f2e1960b06a4053b415bc091a5cbb2439a6ada4299f2a8819e1fa0f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\r\n",
      "Successfully built ta\r\n",
      "Installing collected packages: vnstock, ta\r\n",
      "Successfully installed ta-0.11.0 vnstock-0.2.9.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna joblib xgboost ta vnstock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2d2834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:15.076755Z",
     "iopub.status.busy": "2024-07-04T11:05:15.076391Z",
     "iopub.status.idle": "2024-07-04T11:05:29.354812Z",
     "shell.execute_reply": "2024-07-04T11:05:29.353750Z"
    },
    "id": "gpQcYaNLXb4K",
    "outputId": "206fd270-f538-445e-cc3a-d05a2d9136c3",
    "papermill": {
     "duration": 14.297196,
     "end_time": "2024-07-04T11:05:29.357159",
     "exception": false,
     "start_time": "2024-07-04T11:05:15.059963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas-ta\r\n",
      "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from pandas-ta) (2.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->pandas-ta) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->pandas-ta) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->pandas-ta) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->pandas-ta) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->pandas-ta) (1.16.0)\r\n",
      "Building wheels for collected packages: pandas-ta\r\n",
      "  Building wheel for pandas-ta (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pandas-ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218910 sha256=6c9c0236980837a01825ef08226bc54f52da64ccd82b25b48996446ce1eefd55\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/00/ac/f7fa862c34b0e2ef320175100c233377b4c558944f12474cf0\r\n",
      "Successfully built pandas-ta\r\n",
      "Installing collected packages: pandas-ta\r\n",
      "Successfully installed pandas-ta-0.3.14b0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas-ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3514f946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:29.392514Z",
     "iopub.status.busy": "2024-07-04T11:05:29.391761Z",
     "iopub.status.idle": "2024-07-04T11:05:31.600807Z",
     "shell.execute_reply": "2024-07-04T11:05:31.599778Z"
    },
    "id": "-6lzb3uQqm_5",
    "papermill": {
     "duration": 2.229011,
     "end_time": "2024-07-04T11:05:31.603321",
     "exception": false,
     "start_time": "2024-07-04T11:05:29.374310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import optuna\n",
    "import joblib\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07e9475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:31.638052Z",
     "iopub.status.busy": "2024-07-04T11:05:31.637017Z",
     "iopub.status.idle": "2024-07-04T11:05:32.082468Z",
     "shell.execute_reply": "2024-07-04T11:05:32.081451Z"
    },
    "id": "BOUmyN92qm_6",
    "papermill": {
     "duration": 0.465162,
     "end_time": "2024-07-04T11:05:32.084890",
     "exception": false,
     "start_time": "2024-07-04T11:05:31.619728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "from ta import add_all_ta_features\n",
    "import pandas_ta as ta\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5335f86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.119011Z",
     "iopub.status.busy": "2024-07-04T11:05:32.118644Z",
     "iopub.status.idle": "2024-07-04T11:05:32.123117Z",
     "shell.execute_reply": "2024-07-04T11:05:32.122174Z"
    },
    "id": "8WDgqNpBqm_7",
    "papermill": {
     "duration": 0.023806,
     "end_time": "2024-07-04T11:05:32.125108",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.101302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2383a83c",
   "metadata": {
    "id": "1AoNRGHXqm_7",
    "papermill": {
     "duration": 0.015781,
     "end_time": "2024-07-04T11:05:32.157089",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.141308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d407a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.191027Z",
     "iopub.status.busy": "2024-07-04T11:05:32.190661Z",
     "iopub.status.idle": "2024-07-04T11:05:32.195243Z",
     "shell.execute_reply": "2024-07-04T11:05:32.194284Z"
    },
    "id": "U_IayMGGqm_7",
    "papermill": {
     "duration": 0.023983,
     "end_time": "2024-07-04T11:05:32.197353",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.173370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_storage = os.path.join(\"d:\", \"data\")\n",
    "vn30f_storage = os.path.join(current_storage, 'vn30f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06563fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.231987Z",
     "iopub.status.busy": "2024-07-04T11:05:32.231156Z",
     "iopub.status.idle": "2024-07-04T11:05:32.235882Z",
     "shell.execute_reply": "2024-07-04T11:05:32.234945Z"
    },
    "id": "xEfE2-HKqm_7",
    "papermill": {
     "duration": 0.024466,
     "end_time": "2024-07-04T11:05:32.237938",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.213472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "now_time = 9999999999\n",
    "symbol = 'VN30F1M'\n",
    "rolling_window = 1 # Số phút muốn dự đoán tiếp theo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b7d5ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.272153Z",
     "iopub.status.busy": "2024-07-04T11:05:32.271781Z",
     "iopub.status.idle": "2024-07-04T11:05:32.276756Z",
     "shell.execute_reply": "2024-07-04T11:05:32.275817Z"
    },
    "id": "RpHTaKY6qm_9",
    "papermill": {
     "duration": 0.024481,
     "end_time": "2024-07-04T11:05:32.278839",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.254358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add stream handler of stdout to show the messages\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = \"btc1-study\"  # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8a3f5",
   "metadata": {
    "id": "cWnAMLgxqm_9",
    "papermill": {
     "duration": 0.016,
     "end_time": "2024-07-04T11:05:32.311229",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.295229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac5f543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.345340Z",
     "iopub.status.busy": "2024-07-04T11:05:32.344948Z",
     "iopub.status.idle": "2024-07-04T11:05:32.350128Z",
     "shell.execute_reply": "2024-07-04T11:05:32.349213Z"
    },
    "id": "nkBSamYkqm_9",
    "papermill": {
     "duration": 0.024728,
     "end_time": "2024-07-04T11:05:32.352313",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.327585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def choose_position(roi, trade_threshold = 0.0005):\n",
    "    pos =0\n",
    "    # Predict position base on change in future\n",
    "    if roi > trade_threshold:\n",
    "        pos = 1\n",
    "    elif roi < -trade_threshold:\n",
    "        pos = -1\n",
    "    else:\n",
    "        pos = 0\n",
    "\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25814e68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.386818Z",
     "iopub.status.busy": "2024-07-04T11:05:32.386459Z",
     "iopub.status.idle": "2024-07-04T11:05:32.392998Z",
     "shell.execute_reply": "2024-07-04T11:05:32.391959Z"
    },
    "id": "DvQTvE_-qm_-",
    "papermill": {
     "duration": 0.026249,
     "end_time": "2024-07-04T11:05:32.395069",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.368820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def backtest_position_ps(position, price, percentage, periods):\n",
    "    # Shift positions to align with future price changes and handle NaN by filling with 0\n",
    "    pos = pd.Series(position, index=pd.Series(price).index).shift(1).fillna(0)\n",
    "    pos = pd.Series(pos).rolling(periods).sum() #pos for 10 hour predict\n",
    "\n",
    "    price_array = pd.Series(price).shift(1).fillna(0)\n",
    "\n",
    "    pos_diff = pos.diff()\n",
    "    fee = pos_diff*price_array*0.05*0.01\n",
    "\n",
    "    # Calculate price changes over the given periods\n",
    "    ch = pd.Series(price) - price_array\n",
    "\n",
    "    # Calculate total PnL\n",
    "    total_pnl = pos*ch - fee\n",
    "    return total_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfefb687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.429899Z",
     "iopub.status.busy": "2024-07-04T11:05:32.429027Z",
     "iopub.status.idle": "2024-07-04T11:05:32.434401Z",
     "shell.execute_reply": "2024-07-04T11:05:32.433450Z"
    },
    "id": "KBSYVj2Eqm_-",
    "papermill": {
     "duration": 0.024907,
     "end_time": "2024-07-04T11:05:32.436465",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.411558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_sharpe_ratio(pnl):\n",
    "    pnl = np.diff(pnl)\n",
    "    std = np.std(pnl) if np.std(pnl) != 0 else 0.001\n",
    "    sharpe = np.mean(pnl)/std*np.sqrt(252)\n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58500523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.471038Z",
     "iopub.status.busy": "2024-07-04T11:05:32.470681Z",
     "iopub.status.idle": "2024-07-04T11:05:32.477097Z",
     "shell.execute_reply": "2024-07-04T11:05:32.476190Z"
    },
    "id": "R6Wk1h4Bqm_-",
    "papermill": {
     "duration": 0.026064,
     "end_time": "2024-07-04T11:05:32.479086",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.453022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sharpe_for_vn30f(y_pred, y_price, trade_threshold, fee_perc, periods):\n",
    "\n",
    "    # Predict position base on change in future\n",
    "    pos = [choose_position(roi, trade_threshold) for roi in y_pred]\n",
    "    pos = np.array(pos)\n",
    "\n",
    "    # Calculate PNL\n",
    "    pnl = backtest_position_ps(pos, y_price, fee_perc, periods)\n",
    "    pnl = np.cumsum(pnl)\n",
    "\n",
    "    # Standardalize PNL to date\n",
    "    daily_pnl = [pnl.iloc[i] for i in range(0, len(pnl), 241)]\n",
    "    daily_pnl = pd.Series(daily_pnl).fillna(0)\n",
    "\n",
    "    # Calculate Sharpe\n",
    "    sharpe = calculate_sharpe_ratio(daily_pnl)\n",
    "\n",
    "    return pos, pnl, daily_pnl, sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e48ff962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.514096Z",
     "iopub.status.busy": "2024-07-04T11:05:32.513415Z",
     "iopub.status.idle": "2024-07-04T11:05:32.518738Z",
     "shell.execute_reply": "2024-07-04T11:05:32.517799Z"
    },
    "id": "tFGU3CMsqm__",
    "papermill": {
     "duration": 0.024722,
     "end_time": "2024-07-04T11:05:32.520652",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.495930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_hitrate(pos_predict, pos_true):\n",
    "    if len(pos_predict) != len(pos_true):\n",
    "        raise ValueError(\"Độ dài của hai mảng không khớp\")\n",
    "\n",
    "    # Tính số lượng dự đoán đúng (các phần tử tương ứng giống nhau)\n",
    "    correct_predictions = np.sum(pos_predict == pos_true)\n",
    "\n",
    "    # Tính tỷ lệ hit rate\n",
    "    hit_rate_value = correct_predictions / len(pos_predict)\n",
    "\n",
    "    return hit_rate_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca6edc",
   "metadata": {
    "id": "fmDF4G5hqm__",
    "papermill": {
     "duration": 0.016082,
     "end_time": "2024-07-04T11:05:32.553209",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.537127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Function for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30042319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.587897Z",
     "iopub.status.busy": "2024-07-04T11:05:32.587024Z",
     "iopub.status.idle": "2024-07-04T11:05:32.592639Z",
     "shell.execute_reply": "2024-07-04T11:05:32.591701Z"
    },
    "id": "aBNzE_Pkqm__",
    "papermill": {
     "duration": 0.025162,
     "end_time": "2024-07-04T11:05:32.594775",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.569613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data = np.where(np.isinf(data), np.nan, data)\n",
    "    data = pd.DataFrame(data)\n",
    "    data = data.fillna(0)\n",
    "    scaler.fit(data)\n",
    "    data=pd.DataFrame(scaler.transform(data), index=data.index, columns=data.columns)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2efe7c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.629771Z",
     "iopub.status.busy": "2024-07-04T11:05:32.628930Z",
     "iopub.status.idle": "2024-07-04T11:05:32.637751Z",
     "shell.execute_reply": "2024-07-04T11:05:32.636826Z"
    },
    "id": "rqUtt9Jbqm__",
    "papermill": {
     "duration": 0.028191,
     "end_time": "2024-07-04T11:05:32.639638",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.611447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    \"\"\"\n",
    "    Hàm này chia dữ liệu thành 2 phần: tập huấn luyện và tập hold out.\n",
    "\n",
    "    Args:\n",
    "    data (pandas.DataFrame): DataFrame chứa dữ liệu cần chia.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame chứa dữ liệu tập huấn luyện.\n",
    "    pandas.DataFrame: DataFrame chứa dữ liệu tập giữ lại.\n",
    "    \"\"\"\n",
    "    # Chia dữ liệu thành 3 phần\n",
    "    new_part = np.array_split(data, 3)\n",
    "\n",
    "    # Access each part individually\n",
    "    hold_out = new_part[2]\n",
    "    train_data = pd.concat([new_part[0], new_part[1]], axis=0)\n",
    "\n",
    "    return train_data, hold_out\n",
    "\n",
    "def split_optuna_data(data):\n",
    "    \"\"\"\n",
    "    Hàm này chia dữ liệu thành các tập train và test để sử dụng trong quá trình tối ưu hóa bằng Optuna.\n",
    "\n",
    "    Args:\n",
    "    data (pandas.DataFrame): DataFrame chứa dữ liệu cần chia.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame chứa dữ liệu train (đã được chuẩn hóa).\n",
    "    pandas.DataFrame: DataFrame chứa dữ liệu test (đã được chuẩn hóa).\n",
    "    pandas.Series: Series chứa nhãn tương ứng với dữ liệu train.\n",
    "    pandas.Series: Series chứa nhãn tương ứng với dữ liệu test.\n",
    "    \"\"\"\n",
    "    # Chia dữ liệu thành tập train và tập hold out\n",
    "    train_data, _ = split_data(data)\n",
    "\n",
    "    # Loại bỏ các cột không cần thiết\n",
    "    if 'Open' in train_data.columns:\n",
    "        optuna_data = train_data.drop(['Open','High','Low','Close','Volume', 'Return', 'Date', 'time'], axis=1)\n",
    "    else:\n",
    "        optuna_data = train_data.drop(['Close', 'Return', 'Date', 'time'], axis=1)\n",
    "\n",
    "    # Chuẩn hóa dữ liệu\n",
    "    optuna_data = scale_data(optuna_data)\n",
    "\n",
    "    # Chia dữ liệu thành tập train và tập test\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(optuna_data, train_data['Return'], test_size=0.5, shuffle=False)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid, train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61b4df",
   "metadata": {
    "id": "cKojL2mzqm__",
    "papermill": {
     "duration": 0.01657,
     "end_time": "2024-07-04T11:05:32.672773",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.656203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bc1da64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.761558Z",
     "iopub.status.busy": "2024-07-04T11:05:32.761181Z",
     "iopub.status.idle": "2024-07-04T11:05:32.769797Z",
     "shell.execute_reply": "2024-07-04T11:05:32.768900Z"
    },
    "id": "Dwcxd77MRG8v",
    "papermill": {
     "duration": 0.081952,
     "end_time": "2024-07-04T11:05:32.771777",
     "exception": false,
     "start_time": "2024-07-04T11:05:32.689825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vn30f(start_time, now_time, symbol):\n",
    "    def vn30f():\n",
    "            return requests.get(f\"https://services.entrade.com.vn/chart-api/chart?from={start_time}&resolution=1&symbol={symbol}&to={now_time}\").json()\n",
    "    vn30fm = pd.DataFrame(vn30f()).iloc[:,:6]\n",
    "    vn30fm['t'] = vn30fm['t'].astype(int).apply(lambda x: datetime.utcfromtimestamp(x) + timedelta(hours = 7))\n",
    "    vn30fm.columns = ['Date','Open','High','Low','Close','Volume']\n",
    "    ohlc_dict = {\n",
    "        'Open': 'first',\n",
    "        'High': 'max',\n",
    "        'Low': 'min',\n",
    "        'Close': 'last',\n",
    "        'Volume': 'sum',}\n",
    "    vn30fm = pd.DataFrame(vn30f()).iloc[:,:6]\n",
    "    vn30fm['t'] = vn30fm['t'].astype(int).apply(lambda x: datetime.utcfromtimestamp(x) + timedelta(hours = 7))\n",
    "    vn30fm.columns = ['Date','Open','High','Low','Close','Volume']\n",
    "    dt_object = datetime.utcfromtimestamp(start_time) + timedelta(hours = 7)\n",
    "    now_object = datetime.utcfromtimestamp(now_time) + timedelta(hours = 7)\n",
    "\n",
    "    print(f'===> Data {symbol} from {dt_object} to {now_object} has been appended ')\n",
    "\n",
    "    return vn30fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965cbd22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:05:32.807093Z",
     "iopub.status.busy": "2024-07-04T11:05:32.806442Z",
     "iopub.status.idle": "2024-07-04T11:07:42.477171Z",
     "shell.execute_reply": "2024-07-04T11:07:42.475330Z"
    },
    "id": "EptMr4pMcGw9",
    "outputId": "b59357c7-165a-4fd1-8292-3fafe55e556e",
    "papermill": {
     "duration": 129.708788,
     "end_time": "2024-07-04T11:07:42.497387",
     "exception": true,
     "start_time": "2024-07-04T11:05:32.788599",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='services.entrade.com.vn', port=443): Max retries exceeded with url: /chart-api/chart?from=0&resolution=1&symbol=VN30F1M&to=9999999999 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7e2c4b6afee0>, 'Connection to services.entrade.com.vn timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    490\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:1096\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connection.py:212\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x7e2c4b6afee0>, 'Connection to services.entrade.com.vn timed out. (connect timeout=None)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='services.entrade.com.vn', port=443): Max retries exceeded with url: /chart-api/chart?from=0&resolution=1&symbol=VN30F1M&to=9999999999 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7e2c4b6afee0>, 'Connection to services.entrade.com.vn timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_vn30f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnow_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36mget_vn30f\u001b[0;34m(start_time, now_time, symbol)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvn30f\u001b[39m():\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://services.entrade.com.vn/chart-api/chart?from=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&resolution=1&symbol=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&to=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnow_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m----> 4\u001b[0m vn30fm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mvn30f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m6\u001b[39m]\n\u001b[1;32m      5\u001b[0m vn30fm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m vn30fm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: datetime\u001b[38;5;241m.\u001b[39mutcfromtimestamp(x) \u001b[38;5;241m+\u001b[39m timedelta(hours \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m))\n\u001b[1;32m      6\u001b[0m vn30fm\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m, in \u001b[0;36mget_vn30f.<locals>.vn30f\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvn30f\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://services.entrade.com.vn/chart-api/chart?from=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart_time\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m&resolution=1&symbol=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msymbol\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m&to=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnow_time\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='services.entrade.com.vn', port=443): Max retries exceeded with url: /chart-api/chart?from=0&resolution=1&symbol=VN30F1M&to=9999999999 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7e2c4b6afee0>, 'Connection to services.entrade.com.vn timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "df = get_vn30f(start_time, now_time, symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907e2e3",
   "metadata": {
    "id": "MmMI3SbSdanN",
    "outputId": "fa2fd769-1cd0-4423-d012-c00badf1d81d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9670bcb",
   "metadata": {
    "id": "IgUSjj0jDRFl",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Fill missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf5673",
   "metadata": {
    "id": "H8XyGWJ8qm__",
    "outputId": "7587f5e1-1576-4dca-c832-3319dd3581a7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vnstock import stock_historical_data\n",
    "df2 = stock_historical_data(\"VN30F1M\", \"2023-04-01\", \"2023-07-31\", \"3\", 'derivative')\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392868d0",
   "metadata": {
    "id": "WbdOiZFtqnAA",
    "outputId": "08ae9b8d-85ba-40d2-fb33-8393220bf909",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = df2.drop(columns=['ticker'])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54505896",
   "metadata": {
    "id": "DPbd-HATYCdC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp['time'] = pd.to_datetime(temp['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042bb56d",
   "metadata": {
    "id": "O99omUlQOfIJ",
    "outputId": "77443eb2-52c1-4764-e122-7f54c4efd7ce",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "morning_start = pd.Timestamp('09:00:00').time()\n",
    "morning_end = pd.Timestamp('11:30:00').time()\n",
    "afternoon_start = pd.Timestamp('13:00:00').time()\n",
    "afternoon_end = pd.Timestamp('14:30:00').time()\n",
    "ATC = pd.Timestamp('14:45:00').time()\n",
    "\n",
    "time_points = []\n",
    "current_time = morning_start\n",
    "\n",
    "while current_time <= morning_end:\n",
    "    time_points.append(current_time)\n",
    "    current_time = (pd.Timestamp.combine(pd.Timestamp.today(), current_time) + pd.Timedelta(minutes=1)).time()\n",
    "\n",
    "current_time = afternoon_start\n",
    "while current_time <= afternoon_end:\n",
    "    time_points.append(current_time)\n",
    "    current_time = (pd.Timestamp.combine(pd.Timestamp.today(), current_time) + pd.Timedelta(minutes=1)).time()\n",
    "\n",
    "current_time = ATC\n",
    "while current_time == ATC:\n",
    "    time_points.append(current_time)\n",
    "    current_time = (pd.Timestamp.combine(pd.Timestamp.today(), current_time) + pd.Timedelta(minutes=1)).time()\n",
    "\n",
    "temp = temp.set_index('time')\n",
    "df_resampled = temp.resample('1T').first().reindex(pd.date_range(start=temp.index[0], end=temp.index[-1], freq='1T')).ffill()\n",
    "\n",
    "df_resampled = df_resampled.reset_index().rename(columns={'index': 'time'})\n",
    "temp = temp.reset_index().rename(columns={'index': 'time'})\n",
    "\n",
    "df_resampled = df_resampled[df_resampled['time'].dt.time.isin(time_points)]\n",
    "df_resampled = df_resampled.rename(columns={\n",
    "    'time': 'Date',\n",
    "    'open': 'Open',\n",
    "    'high': 'High',\n",
    "    'low': 'Low',\n",
    "    'close': 'Close',\n",
    "    'volume': 'Volume'\n",
    "})\n",
    "\n",
    "# Divide the Volume column by 3 and round to the nearest integer\n",
    "df_resampled['Volume'] = df_resampled.apply(\n",
    "    lambda row: round(row['Volume'] / 3) if row['Date'].time() < pd.Timestamp('14:30:00').time() else row['Volume'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d91c3",
   "metadata": {
    "id": "v2xKpEoSR3i9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "combined_data = pd.merge(df, df_resampled, on='Date', how='outer', suffixes=('', '_data1'))\n",
    "\n",
    "for column in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "    combined_data[column].fillna(combined_data[f'{column}_data1'], inplace=True)\n",
    "\n",
    "combined_data.drop(columns=[f'{column}_data1' for column in ['Open', 'High', 'Low', 'Close', 'Volume']], inplace=True)\n",
    "\n",
    "\n",
    "combined_data.sort_values('Date', inplace=True)\n",
    "\n",
    "combined_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a2a78",
   "metadata": {
    "id": "_2VBuWNrSJQ-",
    "outputId": "e95a0396-21df-4677-ae1e-5e975f9138ec",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc833068",
   "metadata": {
    "id": "Ry5XUuzySfKG",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99400324",
   "metadata": {
    "id": "3CiXOqameGVO",
    "outputId": "3ce99165-e80b-413d-84aa-8e400b3cb69a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\n",
    "    (df['Date'] >= '2023-04-01') & (df['Date'] <= '2023-08-01')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f516f5",
   "metadata": {
    "id": "-e_nadYJDRFn",
    "outputId": "57eec791-7d6f-4e89-b52c-b1432206f856",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\n",
    "    (data['Date'] >= '2023-04-01') & (data['Date'] <= '2023-08-01')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d40be",
   "metadata": {
    "id": "CVnajMk3qnAA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf85b6f",
   "metadata": {
    "id": "ujwxx5YlqnAA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "# Áp dụng Winsorization\n",
    "data['Close'] = winsorize(data['Close'], limits=[0.05, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38acedad",
   "metadata": {
    "id": "gSLYyILZqnAA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data.set_index('Date', inplace =True)\n",
    "    data.columns = ['Open','High','Low','Close','Volume']\n",
    "\n",
    "    data['Date'] = [str(i)[:10] for i in data.index]\n",
    "    data['time'] = [str(i)[11:] for i in data.index]\n",
    "\n",
    "    data = data[~data.index.duplicated(keep='first')] # Handling duplicate\n",
    "    data_model = data.pivot(index = 'Date', columns = 'time', values = ['Open','High','Low','Close','Volume']).ffill(axis = 1).stack().reset_index() # Handling missing values\n",
    "    # data_model.columns = ['Date','time','Close']\n",
    "\n",
    "    return data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f175a36",
   "metadata": {
    "id": "rIkgvyquqnAA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = process_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e144114",
   "metadata": {
    "id": "K6SIVJpGqnAA",
    "outputId": "9cc29c72-3c4c-4798-e63e-71cccd2ec513",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215bab44",
   "metadata": {
    "id": "AQlr_9yzqnAA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3763bb",
   "metadata": {
    "id": "H06z83k2bpjv",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def z_score_rolling(series, window=30):\n",
    "    \"\"\"Tính Z-score rolling\"\"\"\n",
    "    mean = series.rolling(window).mean()\n",
    "    std = series.rolling(window).std(ddof=0)\n",
    "    z_score = (series - mean) / std\n",
    "    return z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9ffd7",
   "metadata": {
    "id": "1VS6xEuFqnAB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_features(data, shift=1):\n",
    "    \"\"\"\n",
    "    Hàm này tạo ra các features mới từ dữ liệu cổ phiếu.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): DataFrame chứa dữ liệu cần tạo features, có các cột 'open', 'high', 'low', 'close' và 'volume'.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame đã được mở rộng với các features mới.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    # Thêm tất cả các đặc trưng kỹ thuật từ thư viện TA-Lib\n",
    "    # Bollinger Bands\n",
    "    df['BB_Middle'] = df['Close'].rolling(window=20).mean()\n",
    "    df['BB_Std'] = df['Close'].rolling(window=20).std()\n",
    "    df['BB_Upper'] = df['BB_Middle'] + 2 * df['BB_Std']\n",
    "    df['BB_Lower'] = df['BB_Middle'] - 2 * df['BB_Std']\n",
    "\n",
    "    # RSI\n",
    "    df['RSI'] = ta.rsi(df['Close'], length=14)\n",
    "\n",
    "    # MACD\n",
    "    macd = ta.macd(df['Close'], fast=12, slow=26, signal=9)\n",
    "    df['MACD'] = macd['MACD_12_26_9']\n",
    "    df['MACD_Signal'] = macd['MACDs_12_26_9']\n",
    "    df['MACD_Hist'] = macd['MACDh_12_26_9']\n",
    "\n",
    "    # Stochastic Oscillator\n",
    "    stoch = ta.stoch(df['High'], df['Low'], df['Close'])\n",
    "    df['Stoch_K'] = stoch['STOCHk_14_3_3']\n",
    "    df['Stoch_D'] = stoch['STOCHd_14_3_3']\n",
    "\n",
    "    # ATR\n",
    "    df['ATR'] = ta.atr(df['High'], df['Low'], df['Close'], length=14)\n",
    "\n",
    "    # Z-score rolling\n",
    "    df['Z_Score_Rolling'] = z_score_rolling(df['Close'], window=30)\n",
    "\n",
    "    # Percent Change 5 minutes\n",
    "    df['Trend_5min'] = df['Close'].pct_change(periods=5)\n",
    "\n",
    "    # Rolling Standard Deviation 30 minutes\n",
    "    df['Std_Rolling_30min'] = df['Close'].rolling(window=30).std()\n",
    "\n",
    "    # Difference between Close and 30 minutes Moving Average\n",
    "    ma_30min = df['Close'].rolling(window=30).mean()\n",
    "    df['Close_Minus_MA_30min'] = df['Close'] - ma_30min\n",
    "\n",
    "    # Simple Moving Average 10 minutes\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "\n",
    "    df_ta = df.copy()\n",
    "    df_ta.ta.cores = 0\n",
    "    df_ta.ta.strategy('common')\n",
    "\n",
    "    cols_to_drop = ['Open', 'High', 'Low', 'Close', 'Volume', 'Date', 'time']\n",
    "    df_ta = df_ta.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    # Concatenate original dataframe with features from pandas-ta\n",
    "    df = pd.concat([df, df_ta], axis=1)\n",
    "\n",
    "    # Replace infinite values and fill NaN values with 0\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    df2 = data.copy()\n",
    "    df2 = add_all_ta_features(df2, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\")\n",
    "    df2 = df2.drop(columns=['Date','time', 'Open','High','Low','Close','Volume'])\n",
    "\n",
    "    df3 = pd.concat([df, df2], axis=1)\n",
    "\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d504d7d",
   "metadata": {
    "id": "IGxFy81RqnAB",
    "outputId": "9a8f8469-bbdc-4b98-8a24-db0b57ef333e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data  = generate_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa008a",
   "metadata": {
    "id": "gQzKrJCjqnAB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Thêm các feature khác, ví dụ giá vàng (xem xét phù hợp với thời gian trong data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcaa9d0",
   "metadata": {
    "id": "nVQerGPmqnAC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd4f117",
   "metadata": {
    "id": "-9nK3_PfqnAC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_high_corr_columns(df, threshold=0.6):\n",
    "    ohlcv_columns = {'Date','time', 'Open','High','Low','Close','Volume'}\n",
    "\n",
    "     # Identify non-OHLCV and non-date/time columns\n",
    "    non_corr_columns = [col for col in df.columns if col not in ohlcv_columns]\n",
    "\n",
    "    # Compute the correlation matrix only for non-OHLCV and non-date/time columns\n",
    "    corr_matrix = df[non_corr_columns].corr().abs()\n",
    "\n",
    "    # Create a set to keep track of columns to drop\n",
    "    to_drop = set()\n",
    "\n",
    "    # Iterate over the upper triangle of the correlation matrix\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i + 1, len(corr_matrix.columns)):\n",
    "            if corr_matrix.iloc[i, j] > threshold:\n",
    "                # If the correlation is higher than the threshold, mark the column with the higher index to drop\n",
    "                col_to_drop = corr_matrix.columns[j]\n",
    "                if col_to_drop not in ohlcv_columns:\n",
    "                    to_drop.add(col_to_drop)\n",
    "\n",
    "    # Drop the columns from the DataFrame\n",
    "    df_dropped = df.drop(columns=to_drop)\n",
    "    return df_dropped\n",
    "\n",
    "data = drop_high_corr_columns(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2bf2e",
   "metadata": {
    "id": "9DFSNfJOqnAB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Add Predict Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe125027",
   "metadata": {
    "id": "nh3vE-96YUzQ",
    "outputId": "1f7ccdbb-4210-4011-d586-19b532abc0b0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['Return'] = (data['Close'].shift(-rolling_window) - data['Close'])/data['Close']\n",
    "data = data.fillna(0)\n",
    "data = data.drop(index=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34f505",
   "metadata": {
    "id": "RSoMZtvGYX93",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Select features using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360de9e",
   "metadata": {
    "id": "M3LHQmLyqnAC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial, X_train, X_valid, y_train, y_valid, y_price):\n",
    "\n",
    "    # Select features based on Optuna's suggestions\n",
    "    selected_features = []\n",
    "\n",
    "    at_least_one_feature = False\n",
    "\n",
    "    for col in X_train.columns:\n",
    "        select_feature = trial.suggest_categorical(col, [0, 1])\n",
    "        if select_feature:\n",
    "            selected_features.append(col)\n",
    "            at_least_one_feature = True\n",
    "\n",
    "    # If no feature was selected, force selection of at least one feature\n",
    "    if not at_least_one_feature:\n",
    "        # Randomly select one feature to be included\n",
    "        forced_feature = trial.suggest_categorical('forced_feature', X_train.columns.tolist())\n",
    "        selected_features.append(forced_feature)\n",
    "\n",
    "    for t in trial.study.trials:\n",
    "        if t.state != optuna.trial.TrialState.COMPLETE:\n",
    "            continue\n",
    "        if t.params == trial.params:\n",
    "            return np.nan #t.values  # Return the previous value without re-evaluating i\n",
    "\n",
    "    trade_threshold  = 0.0001\n",
    "\n",
    "    # Use only the selected features in training\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_valid_selected = X_valid[selected_features]\n",
    "\n",
    "    # Train the model\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(X_train_selected)\n",
    "    y_pred_valid = model.predict(X_valid_selected)\n",
    "\n",
    "    _, pos_is, _, sharpe_is = sharpe_for_vn30f(y_pred_train, y_price[:len(y_pred_train)], trade_threshold=trade_threshold, fee_perc=0.01, periods=10)\n",
    "    _, pos_os, _, sharpe_oos = sharpe_for_vn30f(y_pred_valid, y_price[len(y_pred_train):], trade_threshold=trade_threshold, fee_perc=0.01, periods=10)\n",
    "\n",
    "    print('Trade times in sample:',len(pos_is[pos_is != 0]), 'Trade times out sample:',len(pos_os[pos_os != 0]))\n",
    "\n",
    "    return sharpe_oos, abs((abs(sharpe_is / sharpe_oos))-1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid, train_data = split_optuna_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660c7b9",
   "metadata": {
    "id": "JCMZkqqqqnAC",
    "outputId": "6522c662-7a29-4c96-fa2f-14f17c7b904f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"## Define number of trials (no 2)\"\"\"\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(directions=['maximize', 'minimize'])\n",
    "unique_trials = 50\n",
    "\n",
    "while unique_trials > len(set(str(t.params) for t in study.trials)):\n",
    "    study.optimize(lambda trial: objective(trial, X_train, X_valid, y_train, y_valid, train_data['Close']), n_trials=1)\n",
    "    study.trials_dataframe().sort_values('values_0').to_csv('xgb_feature_trials.csv')\n",
    "    joblib.dump(study, 'xgbmodel.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cc279",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "study.trials_dataframe().fillna(0).sort_values('values_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a98ccf",
   "metadata": {
    "id": "DYFKKBhpqnAC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Retrieve Top PNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f488ef8",
   "metadata": {
    "id": "2GOEnQ0GXb4V",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study = joblib.load(open(\"rabmodel.pkl\", \"rb\"))\n",
    "trials = study.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e315d",
   "metadata": {
    "id": "oWzuIq5PqnAC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "completed_trials = [t for t in study.trials if t.values is not None]\n",
    "\n",
    "# Sort the completed trials based on their objective values\n",
    "completed_trials.sort(key=lambda trial: trial.values, reverse=True)\n",
    "\n",
    "# Define top pnl to take for clustering\n",
    "top_trials = completed_trials\n",
    "\n",
    "new_df_no_close_col = data.drop(['Date','time', 'Open','High','Low','Close','Volume', 'Return' ], axis=1)\n",
    "\n",
    "# Extract hyperparameters from top trials\n",
    "top_features_list = []\n",
    "\n",
    "for trial in top_trials:\n",
    "  best_selected_features = [col for idx, col  in enumerate(new_df_no_close_col.columns) if trial.params[idx] == 1] # if bug try change from idx to col\n",
    "  top_features_list.append(best_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a8315",
   "metadata": {
    "id": "cutCw_EwqnAD",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_pnl = []\n",
    "trade_threshold  = 0.0005\n",
    "\n",
    "for best_selected_features in top_features_list:\n",
    "\n",
    "    new_df_selected = data[['Close', 'Return']+best_selected_features]\n",
    "    train_select_col_data, _ = split_data(new_df_selected)\n",
    "\n",
    "    retrain_data = train_select_col_data.drop(['Close', 'Return'], axis=1)\n",
    "    retrain_data = scale_data(retrain_data)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(retrain_data,\n",
    "                                                      train_select_col_data['Return'],\n",
    "                                                      test_size=0.5,shuffle=False)\n",
    "\n",
    "    # Create and train model\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    _, pnl_valid, _, _ = sharpe_for_vn30f(y_pred_valid, y_valid, trade_threshold=trade_threshold, fee_perc=0.01, periods=10)\n",
    "    pnl_valid_no_nan = np.nan_to_num(pnl_valid, nan=0)\n",
    "    top_pnl.append(pnl_valid_no_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9774e1e",
   "metadata": {
    "id": "w2BQiJlWXb4W",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Drop too high correlation PNL array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41153fb5",
   "metadata": {
    "id": "Q1wekTJXXb4W",
    "outputId": "71cbe74d-b9e6-49f5-eb82-ccc398a560d9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pnl = pd.DataFrame(top_pnl)\n",
    "pnl = pnl.transpose()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = pnl.corr().abs()\n",
    "\n",
    "# Create a mask to only look at the upper triangle (to avoid duplicate checks)\n",
    "upper_triangle_mask = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Identify columns to drop\n",
    "to_drop = [column for column in upper_triangle_mask.columns if any(upper_triangle_mask[column] > 0.95)]\n",
    "\n",
    "# Drop the columns with high correlation\n",
    "pnl_dropped = pnl.drop(columns=to_drop)\n",
    "\n",
    "print(\"Columns to drop:\", to_drop)\n",
    "print(\"DataFrame after dropping columns:\")\n",
    "print(pnl_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e80be62",
   "metadata": {
    "id": "pf9Imd4uXb4W",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pnl_array = np.array(pnl_dropped.transpose())\n",
    "pnl_array = pnl_array[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d21c11",
   "metadata": {
    "id": "N33x29M6Xb4W",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify columns with all zero values\n",
    "cols_to_keep = ~np.all(pnl_array == 0, axis=0)\n",
    "\n",
    "# Drop columns with all zero values\n",
    "pnl_array = pnl_array[:, cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9012012",
   "metadata": {
    "id": "l8vKyBBgqnAH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# ONC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c0d01",
   "metadata": {
    "id": "TPd5wBN9qnAH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf45e2e",
   "metadata": {
    "id": "0st2dHHbqnAH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cov2corr(cov):\n",
    "    # Derive the correlation matrix from a covariance matrix\n",
    "    std = np.sqrt(np.diag(cov))\n",
    "    corr = cov/np.outer(std,std)\n",
    "    corr[corr<-1], corr[corr>1] = -1,1 #for numerical errors\n",
    "    return corr\n",
    "\n",
    "def clusterKMeansBase(corr0, maxNumClusters=10, n_init=10, debug=False):\n",
    "    corr0[corr0 > 1] = 1\n",
    "    dist_matrix = ((1-corr0)/2.)**.5\n",
    "    silh_coef_optimal = pd.Series(dtype='float64') #observations matrixs\n",
    "    kmeans, stat = None, None\n",
    "    maxNumClusters = min(maxNumClusters, int(np.floor(dist_matrix.shape[0]/2)))\n",
    "    print(\"maxNumClusters\"+str(maxNumClusters))\n",
    "    for init in range(0, n_init):\n",
    "    #The [outer] loop repeats the first loop multiple times, thereby obtaining different initializations. Ref: de Prado and Lewis (2018)\n",
    "    #DETECTION OF FALSE INVESTMENT STRATEGIES USING UNSUPERVISED LEARNING METHODS\n",
    "        for num_clusters in range(2, maxNumClusters+1):\n",
    "            #(maxNumClusters + 2 - num_clusters) # go in reverse order to view more sub-optimal solutions\n",
    "            kmeans_ = KMeans(n_clusters=num_clusters, n_init=10)\n",
    "            #, random_state=3425) #n_jobs=None #n_jobs=None - use all CPUs\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            dist_matrix = imputer.fit_transform(dist_matrix)\n",
    "            kmeans_ = kmeans_.fit(dist_matrix)\n",
    "            silh_coef = silhouette_samples(dist_matrix, kmeans_.labels_)\n",
    "            stat = (silh_coef.mean()/silh_coef.std(), silh_coef_optimal.mean()/silh_coef_optimal.std())\n",
    "\n",
    "            # If this metric better than the previous set as the optimal number of clusters\n",
    "            if np.isnan(stat[1]) or stat[0] > stat[1]:\n",
    "                silh_coef_optimal = silh_coef\n",
    "                kmeans = kmeans_\n",
    "                if debug==True:\n",
    "                    print(kmeans)\n",
    "                    print(stat)\n",
    "                    silhouette_avg = silhouette_score(dist_matrix, kmeans_.labels_)\n",
    "                    print(\"For n_clusters =\"+ str(num_clusters)+ \"The average silhouette_score is :\"+ str(silhouette_avg))\n",
    "                    print(\"********\")\n",
    "\n",
    "    newIdx = np.argsort(kmeans.labels_)\n",
    "    #print(newIdx)\n",
    "\n",
    "    corr1 = corr0.iloc[newIdx] #reorder rows\n",
    "    corr1 = corr1.iloc[:, newIdx] #reorder columns\n",
    "\n",
    "    clstrs = {i:corr0.columns[np.where(kmeans.labels_==i)[0]].tolist() for i in np.unique(kmeans.labels_)} #cluster members\n",
    "    silh_coef_optimal = pd.Series(silh_coef_optimal, index=dist_matrix.index)\n",
    "\n",
    "    return corr1, clstrs, silh_coef_optimal\n",
    "\n",
    "def makeNewOutputs(corr0, clstrs, clstrs2):\n",
    "    clstrsNew, newIdx = {}, []\n",
    "    for i in clstrs.keys():\n",
    "        clstrsNew[len(clstrsNew.keys())] = list(clstrs[i])\n",
    "\n",
    "    for i in clstrs2.keys():\n",
    "        clstrsNew[len(clstrsNew.keys())] = list(clstrs2[i])\n",
    "\n",
    "    newIdx = [j for i in clstrsNew for j in clstrsNew[i]]\n",
    "    corrNew = corr0.loc[newIdx, newIdx]\n",
    "\n",
    "    dist = ((1 - corr0) / 2.)**.5\n",
    "    kmeans_labels = np.zeros(len(dist.columns))\n",
    "    for i in clstrsNew.keys():\n",
    "        idxs = [dist.index.get_loc(k) for k in clstrsNew[i]]\n",
    "        kmeans_labels[idxs] = i\n",
    "\n",
    "#     silhNew = pd.Series(silhouette_samples(dist, kmeans_labels), index=dist.index)\n",
    "    silhNew = pd.Series(silhouette_samples(dist, kmeans_labels), index=dist.index)\n",
    "    return corrNew, clstrsNew, silhNew\n",
    "\n",
    "def clusterKMeansTop(corr0: pd.DataFrame, maxNumClusters=None, n_init=10):\n",
    "    if maxNumClusters == None:\n",
    "        maxNumClusters = corr0.shape[1]-1\n",
    "\n",
    "    corr1, clstrs, silh = clusterKMeansBase(corr0, maxNumClusters=min(maxNumClusters, corr0.shape[1]-1), n_init=10)#n_init)\n",
    "    print(\"clstrs length:\"+str(len(clstrs.keys())))\n",
    "    print(\"best clustr:\"+str(len(clstrs.keys())))\n",
    "    #for i in clstrs.keys():\n",
    "    #    print(\"std:\"+str(np.std(silh[clstrs[i]])))\n",
    "\n",
    "    clusterTstats = {i:np.mean(silh[clstrs[i]])/np.std(silh[clstrs[i]]) for i in clstrs.keys()}\n",
    "    tStatMean = np.sum(list(clusterTstats.values()))/len(clusterTstats)\n",
    "    redoClusters = [i for i in clusterTstats.keys() if clusterTstats[i] < tStatMean]\n",
    "    #print(\"redo cluster:\"+str(redoClusters))\n",
    "    if len(redoClusters) <= 2:\n",
    "        print(\"If 2 or less clusters have a quality rating less than the average then stop.\")\n",
    "        print(\"redoCluster <=1:\"+str(redoClusters)+\" clstrs len:\"+str(len(clstrs.keys())))\n",
    "        return corr1, clstrs, silh\n",
    "    else:\n",
    "        keysRedo = [j for i in redoClusters for j in clstrs[i]]\n",
    "        corrTmp = corr0.loc[keysRedo, keysRedo]\n",
    "        _, clstrs2, _ = clusterKMeansTop(corrTmp, maxNumClusters=min(maxNumClusters, corrTmp.shape[1]-1), n_init=n_init)\n",
    "        print(\"clstrs2.len, stat:\"+str(len(clstrs2.keys())))\n",
    "        #Make new outputs, if necessary\n",
    "        dict_redo_clstrs = {i:clstrs[i] for i in clstrs.keys() if i not in redoClusters}\n",
    "        corrNew, clstrsNew, silhNew = makeNewOutputs(corr0, dict_redo_clstrs, clstrs2)\n",
    "        newTstatMean = np.mean([np.mean(silhNew[clstrsNew[i]])/np.std(silhNew[clstrsNew[i]]) for i in clstrsNew.keys()])\n",
    "        if newTstatMean <= tStatMean:\n",
    "            print(\"newTstatMean <= tStatMean\"+str(newTstatMean)+ \" (len:newClst)\"+str(len(clstrsNew.keys()))+\" <= \"+str(tStatMean)+ \" (len:Clst)\"+str(len(clstrs.keys())))\n",
    "            return corr1, clstrs, silh\n",
    "        else:\n",
    "            print(\"newTstatMean > tStatMean\"+str(newTstatMean)+ \" (len:newClst)\"+str(len(clstrsNew.keys()))\n",
    "                  +\" > \"+str(tStatMean)+ \" (len:Clst)\"+str(len(clstrs.keys())))\n",
    "            return corrNew, clstrsNew, silhNew\n",
    "            #return corr1, clstrs, silh, stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74a329",
   "metadata": {
    "id": "7FqBCm3aqnAI",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FREQUENCY FEATURE TABLE\n",
    "correlation_matrix = np.corrcoef(top_pnl)\n",
    "corr = pd.DataFrame(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347d65b",
   "metadata": {
    "id": "T5xhYDxSqnAI",
    "outputId": "8e320ecd-3068-4cc2-8563-29ea82274ec2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Draw ground truth\n",
    "matplotlib.pyplot.matshow(corr) #invert y-axis to get origo at lower left corner\n",
    "matplotlib.pyplot.gca().xaxis.tick_bottom()\n",
    "matplotlib.pyplot.gca().invert_yaxis()\n",
    "matplotlib.pyplot.colorbar()\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "#draw prediction based on ONC\n",
    "corrNew, clstrsNew, silhNew = clusterKMeansTop(corr)\n",
    "matplotlib.pyplot.matshow(corrNew)\n",
    "matplotlib.pyplot.gca().xaxis.tick_bottom()\n",
    "matplotlib.pyplot.gca().invert_yaxis()\n",
    "matplotlib.pyplot.colorbar()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed0886",
   "metadata": {
    "id": "WqXnwhndqnAJ",
    "outputId": "9d773038-928f-4d8e-ca6e-92b8e6c48bd9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_lists = []\n",
    "\n",
    "# Iterate through each cluster and its members\n",
    "for cluster_number, cluster_indices in clstrsNew.items():\n",
    "    cluster_list = []\n",
    "\n",
    "    # Iterate through each index in the cluster\n",
    "    for idx in cluster_indices:\n",
    "        trial_number = top_trials[idx].number\n",
    "        cluster_list.append(trial_number)\n",
    "\n",
    "    cluster_lists.append(cluster_list)\n",
    "\n",
    "# Print the lists for each cluster\n",
    "for i, cluster_list in enumerate(cluster_lists):\n",
    "    print(f\"Cluster {i}: {cluster_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a88244",
   "metadata": {
    "id": "mWNyvwA_qnAJ",
    "outputId": "d7fe29f8-120f-4418-8bed-0c959bcc54c2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_10_features_per_cluster = []\n",
    "\n",
    "for cluster_number, cluster_indices in clstrsNew.items():\n",
    "    cluster_frequency = {}\n",
    "\n",
    "    for idx in cluster_indices:\n",
    "        trial_params = top_trials[idx].params\n",
    "        for key, value in trial_params.items():\n",
    "            if value == 1:\n",
    "                cluster_frequency[key] = cluster_frequency.get(key, 0) + 1\n",
    "\n",
    "    sorted_cluster_frequency = sorted(cluster_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_10_features_cluster = [feature for feature, _ in sorted_cluster_frequency[:10]]\n",
    "    top_10_features_per_cluster.append(top_10_features_cluster)\n",
    "    print(f\"Top 10 features for Cluster {cluster_number}: {top_10_features_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f45739",
   "metadata": {
    "id": "mrqWExveqnAJ",
    "outputId": "d389b5ae-50a9-4df1-a572-52518f381b94",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_10_features_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd8ed9",
   "metadata": {
    "id": "RbGe0Y6FqnAK",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top10_feat = pd.DataFrame(top_10_features_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d7549",
   "metadata": {
    "id": "2_DrQbneqnAK",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_columns_cluster = []\n",
    "for item in top_10_features_per_cluster:\n",
    "  selected_columns = new_df_no_close_col.iloc[:, item]\n",
    "  selected_columns_cluster.append(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230015c6",
   "metadata": {
    "id": "tMmpd-7pLkrQ",
    "outputId": "2b40d40e-9967-4f72-a89c-397850f580c2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_columns_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977bfd34",
   "metadata": {
    "id": "tuOGlO_tqnAK",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b7134",
   "metadata": {
    "id": "rxwojZV6qnAK",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Custom Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644028fa",
   "metadata": {
    "id": "FSf9W4XzqnAL",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ab6eb",
   "metadata": {
    "id": "CUVrgTA4qnAL",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_delta = 0.0001\n",
    "patience = 30\n",
    "\n",
    "\n",
    "class CustomEarlyStopping(callback.TrainingCallback):\n",
    "    def __init__(self, min_delta, patience, verbose=False):\n",
    "        super().__init__()\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.best_score = np.inf\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        if not evals_log:\n",
    "            return False\n",
    "        metric_name = next(iter(evals_log['validation_0']))\n",
    "        score = evals_log['validation_0'][metric_name][-1]\n",
    "        if score < (self.best_score - self.min_delta):\n",
    "            self.best_score = score\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print(f\"\\nStopping. Best score: {self.best_score}\")\n",
    "                self.stopped_epoch = epoch\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_best_score(self):\n",
    "        return self.best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85792fd9",
   "metadata": {
    "id": "VNG_94woqnAL",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fc5de",
   "metadata": {
    "id": "T0bcD4ZRqnAL",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_params(trial, X_train, X_valid, y_train, y_valid, y_close):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'n_estimators': 8000,  # does not matter, think of it as max epochs, and we stop the model based on early stopping, so any extremely high number works\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # can't comment, never played with that\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # you dont want to sample less than 50% of your data\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),  # you dont want to sample less than 30% of your features pr boosting round\n",
    "        }\n",
    "    trade_threshold  = 0.0005\n",
    "\n",
    "    # Check duplication and skip if it's detected.\n",
    "    for t in trial.study.trials:\n",
    "        if t.state != optuna.trial.TrialState.COMPLETE:\n",
    "            continue\n",
    "        if t.params == trial.params:\n",
    "            return np.nan #t.values  # Return the previous value without re-evaluating i\n",
    "\n",
    "\n",
    "    custom_early_stopping_instance = CustomEarlyStopping(min_delta=min_delta, patience=patience, verbose=True)\n",
    "\n",
    "    # Train the model\n",
    "    model = DecisionTreeRegressor(**params)\n",
    "    model.fit(X_train, y_train, callbacks=[custom_early_stopping_instance])\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "\n",
    "\n",
    "    pos, pnl, daily_pnl, sharpe_is = sharpe_for_vn30f(y_pred_train, y_close[:len(y_pred_train)], trade_threshold=trade_threshold, fee_perc=0.01, periods=10)\n",
    "    _, _, _, sharpe_oos = sharpe_for_vn30f(y_pred_valid, y_close[len(y_pred_train):], trade_threshold=trade_threshold, fee_perc=0.01, periods=10)\n",
    "\n",
    "    return sharpe_oos, abs((abs(sharpe_is / sharpe_oos))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df067674",
   "metadata": {
    "id": "gKNvShYMqnAM",
    "outputId": "a8eb0472-b604-4434-87c3-18351bbca671",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params_list = []\n",
    "for idx, data_item in enumerate(selected_columns_cluster):\n",
    "    train_cols, _ = split_data(data_item)\n",
    "    optuna_data = scale_data(train_cols)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(optuna_data,\n",
    "                                                            train_data['Return'],\n",
    "                                                            test_size=0.5,\n",
    "                                                            shuffle=False)\n",
    "    study = optuna.create_study(directions=['maximize', 'minimize'])\n",
    "\n",
    "    unique_trials = 100\n",
    "    while unique_trials > len(set(str(t.params) for t in study.trials)):\n",
    "        study.optimize(lambda trial: objective_params(trial, X_train, X_valid, y_train, y_valid, train_data['Close']), n_trials=1)\n",
    "\n",
    "    # Retrieve all trials\n",
    "    trials = study.trials\n",
    "\n",
    "    completed_trials = [t for t in study.trials if t.values is not None]\n",
    "\n",
    "    # Sort trials based on objective values\n",
    "    completed_trials.sort(key=lambda trial: trial.values, reverse=True)\n",
    "\n",
    "    # Select top 1 trials\n",
    "    params = completed_trials[0].params\n",
    "    best_params_list.append(params)\n",
    "\n",
    "    model = DecisionTreeRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    model.save_model(f'best_in_cluster_{idx}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c400820a",
   "metadata": {
    "id": "bICDZWmoqnAM",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trials = study.trials\n",
    "# trials.sort(key=lambda trial: trial.values, reverse=True)\n",
    "# study.trials_dataframe().sort_values('values_0', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d03b4",
   "metadata": {
    "id": "ZfJ2jbgfqnAM",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Test and save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b411152",
   "metadata": {
    "id": "FWdWQB46qnAM",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, hold_out = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57a8b4",
   "metadata": {
    "id": "IG-_sUBMqnAN",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_result_df(hold_out, y_hold_out, data, train_data, pos, pnl):\n",
    "    result = pd.DataFrame()\n",
    "    result['Close_Holdout'] = hold_out['Close']\n",
    "    result['Ground_value_Holdout'] = hold_out['Return']\n",
    "    result['Predict_diff_Holdout'] = pd.Series(y_hold_out, index=data.index[len(train_data):len(data)])\n",
    "    result['Position_predict_Holdout'] = pd.Series(pos, index=data.index[len(train_data):len(data)])\n",
    "    result['PNL_Holdout'] = pd.Series(pnl)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb54602",
   "metadata": {
    "id": "tMF5DfvAqnAN",
    "outputId": "79dd049d-40b4-4f0d-992d-40902be6742c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pnl_data = []\n",
    "sharpe_list = []\n",
    "result = None\n",
    "trade_threshold  = 0.0005\n",
    "\n",
    "# Create a single figure and set of subplots\n",
    "fig, axes = plt.subplots(len(selected_columns_cluster), figsize=(10, 12))\n",
    "\n",
    "for idx, data_item in enumerate(selected_columns_cluster):\n",
    "    _, hold_out_cols = split_data(data_item)\n",
    "\n",
    "    xbg_reg = DecisionTreeRegressor()\n",
    "    # Create and train model\n",
    "    xbg_reg.load_model(f\"best_in_cluster_{idx}.json\")\n",
    "\n",
    "    # Make predictions\n",
    "    hold_out_cols.columns = optuna_data.columns\n",
    "    y_hold_out = xbg_reg.predict(hold_out_cols)\n",
    "    pos, pnl, daily, sharpe = sharpe_for_vn30f(y_hold_out, hold_out['Return'], trade_threshold=trade_threshold, fee_perc=0.01, periods=10)\n",
    "\n",
    "    print(f\"Pnl ratio for cluster {idx}: {pnl}\")\n",
    "    # Append PnL data to the list\n",
    "    pnl_data.append(pnl)\n",
    "    result = return_result_df(hold_out, y_hold_out, data, train_data, pos, pnl)\n",
    "    sharpe_list.append(sharpe)\n",
    "    \n",
    "    # Plot PnL for each cluster\n",
    "    if len(selected_columns_cluster) == 1:\n",
    "        ax = axes\n",
    "    else:\n",
    "        ax = axes[idx]\n",
    "\n",
    "    ax.plot(pnl, label=f'Cluster {idx}')\n",
    "    ax.set_title(f'PnL for Cluster {idx}')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('PnL')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f4c8cc",
   "metadata": {
    "id": "MuHQIzsZqnAN",
    "outputId": "33f0b1d4-1ec4-4565-b5be-60293c612b50",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Top 10 feature into list\n",
    "feature=[]\n",
    "for i in top_10_features_per_cluster:\n",
    "    listToStr = ' '.join([str(elem) for elem in i])\n",
    "    feature.append(listToStr)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca6806",
   "metadata": {
    "id": "CYX69HnfqnAN",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "name=[]\n",
    "for i in range(len(selected_columns_cluster)):\n",
    "  name.append( 'Cluster '+ str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c03c6",
   "metadata": {
    "id": "zj3kWFscqnAO",
    "outputId": "804b6e0b-c973-4037-d564-f879dacdad14",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict = {'Top 10 Feature' : feature, 'Best params': best_params_list, 'Best sharpe':sharpe_list}\n",
    "df_result = pd.DataFrame(dict, index=name)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81ebd4",
   "metadata": {
    "id": "gC6RQbaHqnAO",
    "outputId": "b1910dd5-1367-4514-ece4-2c49ef48804c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DataFrame of Pnl hold out\n",
    "df_pnl = pd.DataFrame()\n",
    "for i in range(len(selected_columns_cluster)):\n",
    "  df_pnl[name[i]]=pnl_data[i]\n",
    "df_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4053e8",
   "metadata": {
    "id": "URgaoxghKDDE",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EhK1f5uMqm_4",
    "1AoNRGHXqm_7",
    "cWnAMLgxqm_9"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 165.996455,
   "end_time": "2024-07-04T11:07:43.236715",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-04T11:04:57.240260",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
